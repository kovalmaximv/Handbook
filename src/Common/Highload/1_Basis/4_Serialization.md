[Назад](./README.md)

1. [Введение](#сериализация)
2. [Форматы кодирования данных](#форматы-кодирования-данных)  
   2.1. [Форматы ориентированные на конкретные языки](#форматы-ориентированные-на-конкретные-языки)  
   2.2. [JSON, XML и двоичные типы данных](#json-xml-и-двоичные-типы-данных)  
   2.2. [Thrift и Protocol Buffers](#thrift-и-protocol-buffers)  
3. [Режимы движения данных](#режимы-движения-данных)  
   3.1. [Поток данных через БД](#поток-данных-через-бд)  
   3.2. [Поток данных через REST и RPC](#поток-данных-через-rest-и-rpc)

# Сериализация
Приложения неизбежно обмениваются данными с течением времени. Для отправки данных необходимо выбрать общий формат, 
в который сможет закодировать отправитель и прочитать получатель. Процесс кодирования данных называется _сериализацией_, 
а процесс декодирования - _десериализацией_. Данные неизбежно будут меняться, добавляться новые поля или изменяться 
формат/тип существующих. Поэтому очень важно продумать процесс эволюции кодируемых данных (прямая и обратная 
совместимость данных).  

О сериализация и поддержке эволюции данных пойдет речь в данной главе.

## Форматы кодирования данных
Сериализация или кодирование - процесс преобразования из объектов и структур в памяти в последовательности 
байтов, пригодную для отправки по сети. Обратная операция называется десериализация или декодирование. 

#### Форматы ориентированные на конкретные языки
Во многих языках есть встроенные механизмы сериализации, например как `java.io.Serialization` в Java. Эти механизмы 
удобны тем, что позволяют сериализовать необходимые данные с помощью минимального количества кода. Однако у этого 
механизма есть свои проблемы:
1) Встроенный механизм сериализации может быть привязан к конкретному языку. 
2) Процесс декодирования имеет возможность создавать произвольные классы, что является дырой в безопасности.
3) Контроль версий в этих механизмах зачастую неудобны.
4) Эффективность порой тоже оставляет желать лучшего.

Вследствие этого, использование встроенных механизмов сериализации в долгосрочной перспективе обычно является плохой 
идеей.

#### JSON, XML и двоичные типы данных
JSON, XML и CSV - текстовые универсальные форматы, относительно удобочитаемые для людей. Однако у них есть ряд проблем:
1) **Кодирование чисел** приводит к неоднозначностям. В XML и CSV невозможно различить число и строку, состоящую из цифр.
JSON различает числа и строки, но не различает целые значения и значения с плавающей точкой. Так же существует проблема
относительно больших чисел: если в одном ЯП число валидно, то для другого оно может стать слишком большим. 
2) В XML и JSON есть дополнительная поддержка схемы данных (прямо как в БД), но сложны в использовании.
3) В CSV нет никакой схемы, поэтому тип данных каждого столбца определяет само приложение. 

Но несмотря на эти изъяны, JSON/XML/CSV достаточно хороши для многих целей: они легки в понимание, читаемы для людей и 
выполняют свои формата сериализованных данных. Однако данный формат отнюдь не компактный. Для случаев, когда это важно,
существуют **двоичные форматы** сериализации. Например двоичные форматы JSON (BSON, BJSON, BISON, etc) и XML 
(WBXML, Fast Infoset, etc). Эти форматы применяются в некрупных сегментах рынка и ни один из них не задействован так
широко, как JSON/XML/CSV. 

#### Thrift и Protocol Buffers
Apache Thrift и Protocol Buffers (protobuf) - библиотеки двоичного кодирования для передачи данных. Оба фреймворка
требуют наличия схемы данных для работы. Оба фреймворка содержат утилиту генерации кода, которые на основе схемы 
могут генерировать классы (не только DTO, но и API).

Пример схемы данных Thrift:
```
struct Person {
    1: required string       username,
    2: optional i64          favoriteNumber,
    3: optional list<string> interests
}
```

Закодированная запись представляет собой конкатенацию полей, каждое поле определенно своим номером тега и помечено 
типом данных. Если значение поля не задано, оно просто не включается в закодированную запись. Можно поменять название
полей в схеме, но **нельзя поменять тег поля**, так как из-за этого все уже закодированные данные превратятся в 
неправильные. В схему можно **добавлять новые поля**, но новому полю нужно задать новый порядковый номер тега и нельзя
его делать обязательным, это поломает совместимость. Старый код, для которого еще неизвестно это поле с новым тегом, 
будет его просто игнорировать. Так же можно **удалять поля** их схемы, но можно удалять только необязательные поля 
и нельзя использовать один и тот же номер тега повторно. 

У этих библиотек есть ряд достоинств:
1) Закодированные данные компактнее, чем у двоичного JSON
2) Схема - важный вид документации API
3) Генерация кода

Из минусов можно выделить:
1) Необходимость погружения в технологию для новых разработчиков
2) Меньшая популярность, чем JSON/XML
3) Нечитаемые (для человека) данные, передающиеся по сети

# Режимы движения данных
В предыдущей главе мы узнали с помощью каких технологий можно кодировать данные. В этой главе узнаем, с помощью каких 
технологий можно передавать закодированные данные из одного сервиса в другой. Существует множество вариантов движения 
данных, самые популярные из них:
1) Через БД
2) С помощью вызовов сервисов (REST и RPC)
3) Путем передачи асинхронных сообщений через брокеры

#### Поток данных через БД
Для данного режима движения данных критически важно помнить про прямую и обратную совместимость схемы данных. Так как
в БД могут обращаться несколько сервисов (или инстансов одного сервиса) и у них могут быть разные версии кода. То есть
вполне возможен вариант, когда запись происходит более новой версией кода, а чтение более старой и наоборот. 

Есть еще одна загвоздка. Например новый код вставил запись с новым полем. Эту запись прочитал более старый код (ничего
не знающий про новое поле), изменил запись и сохранил изменение в БД. Нужно быть начеку, чтобы старый код не затер
значение нового поля, про которое он ничего не знает.

Записи в БД могут храниться десятилетиями, поэтому отдельно стоит поговорить про миграцию данных. Для больших таблиц это
ресурсоемкая операция, так что большинство БД по возможности стараются избегать этой операции. Поэтому в большинстве БД
разрешено простые изменения схемы, например добавление нового поля только с дефолтным значением без перезаписи 
существующих данных. 

#### Поток данных через REST и RPC
Существует несколько различных способов организации взаимодействия процессов по сети. Наиболее часто используемый 
вариант включает два вида ролей: клиенты и серверы. Серверы предоставляют видимый по сети API, а клиенты могут к ним 
подключаться и выполнять запросы к этому API. Предоставляемый сервером API называется _сервисом_.

Зачастую, клиентом сервера является веб-браузер, телефон или другое устройство конечного пользователя. Браузер 
при помощи запросов получает необходимую для работы информацию. Клиентом сервера может являться и другой сервер. 
Такой подход используется для декомпозиции больших приложений на небольшие сервисы по областям функциональности (по 
сути в любой крупной компании). Сервисы обращаются друг к другу в случае необходимости получения информации. Подобная
архитектура называется **сервис-ориентированной архитектурой** (service-oriented architecture, SOA), не так давно
ее немного пересмотрели/переработали и назвали **микросервисной архитектурой** (microservice architecture).

Главная цель микросервисной архитектуры - облегчить разработку и поддержку приложения путем обеспечения независимого
развертывания и развития сервисов. Каждый сервис относится к сфере ответственности одной команды разработчиков, которая
должна быть способна выпускать частые релизы с минимальным вмешательством со стороны других команд. Другими словами, 
нужно быть готовым, что старые и новые версии сервисов и клиентов могут жить одновременно. Значит используемые
серверами и клиентами форматы кодирования данных должны быть совместимы между разными версиями API.

Если в качестве базового протокола для связи с сервисом используется HTTP, то такой сервис называется **веб-сервисом**.
Существуют два популярных подхода к проектирования веб-сервиса: **REST** и **SOAP**.

REST не протокол, а скорее подход к проектированию, основанный на принципах HTTP. Он делает акцент на просатых форматах
данных, применении URL для идентификации ресурсов и максимальном использовании возможностей HTTP для прикладных задач. 
REST становится все более популярным по сравнению с SOAP и часто ассоциируется с микросервисами. API спроектированный в 
соответствие с принципами REST называется **RESTful API**.

SOAP - основанный на формате XML протокол для выполнения запросов к API. Применяется чаще всего по HTTP, но старается
использовать минимум возможностей HTTP. Вместо этого, SOAP имеет массу сопутствующих стандартов-фреймворков, которые
добавляют в него различные возможности (WS-*). API SOAP описывается с помощью основанного на XML языка WSDL. Этот язык
позволяет генерировать код, так что клиент может сгенерировать классы для обращения к SOAP API. Поскольку WSDL не 
предназначен для чтения людьми, а SOAP сообщения слишком сложны, чтобы их можно было сформировать вручную, пользователи
SOAP сильно зависят от утилит генерации кода. Хотя SOAP стандартизирован, взаимодействие между его реализациями от 
различных производителей часто приводит к проблемам. В связи с этом SOAP выходит из моды и постепенно вытесняется REST
подходом. 

Таким образом, RESTful API имеет предрасположенность к более простым подходам и использует меньше генерируемого кода и
автоматизированных утилит. Для описаниях RESTful API и создания документации можно применить формат описания 
OpenAPI (известный так же как Swagger).

RPC (remote procedure call) - технология, зародившаяся до REST, SOAP и даже удаленных вызовов методов. Основная идея 
RPC состоит в том, что выполнение запроса к удаленному сервису должна выглядеть так же, как и вызов метода. На первый
взгляд это может показаться удобным, но у такого подхода есть свои недостатки:
1) Локальному вызову метода присуща предсказуемость. Он или завершается успешно, или нет, в зависимости от 
переданных параметров. Сетевой запрос непредсказуем из-за нестабильной природы работы сети. 
2) Локальный вызов может вернуть: результат, исключение или ничего. Сетевой вызов помимо этого может упасть из-за 
таймаута ожидания ответа. И если сервис не вернул никакого результата, вы не сможете узнать, был ли доставлен и выполнен 
запрос? Необходимо ли отправить запрос повторно?
3) Повторяя отправку неудачного сетевого запроса вы должны учитывать, что запросы доставляются, но очень медленно
обрабатываются. Отправив запрос второй раз, вы задублируете данные (если API не идемпотентно). 
4) Каждый вызов локального метода занимают приблизительно одно и то же время. В то время как задержка сетевых запросов
варьируется сильнее.
5) При вызове локального метода можно передать ссылки на объекты. При сетевом вызове объекты придется сериализовывать.

На все предыдущие минусы можно возразить, что в работу локальных методов может внести коррективы железо сервера. Но
в наших реалиях железо перестало быть таким нестабильным, каким было 50 лет назад (при основании RPC технологии). Таким
образом, все приведенные факты говорят, что не стоит пытаться сделать удаленный сервис похожим на вызов локального
метода. Подход REST тем и привлекателен, что не пытается скрыть сетевую природу протокола. Несмотря на все эти проблемы, 
RPC не уходит из индустрии. Существуют популярные фреймворки RPC: gRPC (RPC + Protocol Buffers), Finagle (RPC + Thrift), 
встроенная поддержка RPC в Thrift. Новое поколение фреймворков пытается явно декларировать различие между удаленным 
запросом и локальным вызовом. Для этого используются промисы и фьючеры.

Пользовательские протоколы RPC с двоичным форматом кодирования иногда оказываются быстрее, чем универсальный REST + 
JSON. Однако у RESTful API есть другие важные преимущества: они хороши для тестирования и отладки (запросы можно послать
хоть через curl, вручную составив необходимый JSON), их поддерживают все основные языки программирования и платформы. 
Кроме того, у RESTful API есть большая экосистема вспомогательных утилит.

Таким образом, REST является господствующим стилем написания API. RPC сосредоточен в основном на запросах между 
сервисами одной компании. 

#### Поток передачи данных через асинхронные сообщения
Системы асинхронной передачи сообщений это что-то среднее между REST и БД. Они схожи с REST в том, что запрос от 
клиента (message) доставляется другому процессу без особой задержки. Сходство с БД в том, что сообщение отправляется
через посредника (message broker/queue).

Использование брокера сообщений имеет несколько плюсов:
1) Он служит в качестве буфера в случае недоступности/перегруженности сервиса
2) Повторно отправляет сообщение получателям в случае сбоя (предотвращая потерю сообщений)
3) Отправителю нет нужды знать хост и порт получателя (удобно в облачной среде, где хост и порт часто меняются)
4) Обеспечивает возможность отправки одного сообщения нескольким получателям
5) Логически разделяет получателя и отправителя

Но есть и свой минус: взаимодействие одностороннее. То есть отправитель не узнает, прочитал получатель сообщение или 
нет. Получатель может отправить ответ, но для этого нужен еще один сетевой вызов или отправка сообщения в другую 
очередь.

Существует множество брокеров сообщений (RabbitMQ, ActiveMQ, Kafka, etc). Нюансы модели доставки зависят от конкретного 
брокера, но верхнеуровнего процесс выглядит следующим образом: один процесс отправляет сообщение, предназначенное для
конкретной очереди (queue/topic), брокер обеспечивает отправку этого сообщения одному или нескольким подписчикам 
(consumer/subscriber). У одной очереди можно быть много отправителей и получателей.

Брокеры не навязывают какую-либо модель данных. Сообщения представляют собой просто байтовую последовательность. 

# Резюме
Существует множество форматов кодирования данных, которые преобразовывают объекты из памяти в байтовую последовательность
для дальнейшей отправки по сети. Нюансы этих форматов влияют не только на эффективность, но и на архитектуру приложений.

В случае обновления сервисов нам приходится допускать, что разные инстансы могут использовать разные версии кода. 
Следовательно необходимо сериализовать данные так, чтобы они поддерживали обратную совместимость (новый код может
читать старые данные) и прямую совместимость (старый код может читать новые данные).

Мы рассмотрели несколько форматов кодирования данных:
1) Форматы кодирования определенных языков (из коробки) сильно заточены под конкретный язык, зачастую неэффективны и
не могут обеспечить прямой и/или обратной совместимости.
2) Текстовые форматы JSON/XML/CSV широко распространены и их прямая/обратная совместимость зависит от способа
использования. В этих языках типы данных обычно расплывчаты, стоит держать это в уме при работе с ними.
3) Основанные на двоичном кодировании Thrift, Protocol Buffers позволяют выполнять сжатую и эффективную сериализацию с 
поддержкой прямой и обратной совместимостью (не без своих костылей). Их схемы могут быть полезны для документирования и
генерации кода. Однако данные необходимо декодировать, чтобы человек мог их прочитать.

Так же рассмотрели несколько режимов движения потоков данных:
1) Базы данных 
2) RPC и REST API 
3) Асинхронная передача сообщений