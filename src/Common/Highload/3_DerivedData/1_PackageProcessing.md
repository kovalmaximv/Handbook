# Пакетная обработка
Выделяют 3 типа систем:
1) **Сервисы** (онлайновые системы) - сервис ожидает запроса от клиента. После того, как запрос получен, сервис пытается 
обработать его максимально быстро и возвращает отклик. Отклик является первичной мерой производительности сервиса.
2) **Системы пакетной обработки** - принимает большое количество данных, запускает задачу для их обработки и выдает некие 
данные на выход. Подобные задачи выполняются долго, так что пользователь не ждет их выполнения. Главная мера 
производительности - пропускная способность. **В этой главе мы рассмотрим именно такие системы**.
3) **Системы поточной обработки** - поточная обработка представляет собой что-то среднее между потоковой и онлайновой 
обработкой. Как и при пакетной обработке, эта система принимает данные на входе и генерирует выходные данные. Однако в 
случае появления событий поточные задачи реагируют на них, в то время как пакетные работают только с фиксированным 
набором входных данных.

Системы пакетной обработки используются в компаниях, связанные с аналитикой/обработкой big data. Самый популярные 
алгоритм обработки больших данных является MapReduce (о нем мы поговорим позже). MapReduce используется в Hadoop, 
CouchDB и MongoDB. 

### MapReduce
MapReduce схож по принципу работы с утилитами Unix. Он принимает один или несколько потоков ввода и производит
один или несколько потоков вывода. MapReduce не изменяет входные данные и не имеет побочных эффектов, только генерирует 
выходные данные. При помощи этого алгоритма можно обрабатывать большие объемы данных (петабайты) при помощи распределенной 
вычислительной системы. Реальные примеры использования MapReduce:
1) **Построение поисковых индексов** - когда необходимо выполнить полнотекстовый поиск по фиксированному большому 
количеству документов. MapReduce хорошо паралелит (делит на части) исходный объем текста и анализирует текст по 
кусочкам.
2) **Создание систем машинного обучения** - такие как классификаторы и рекомендательные системы. Результатом выполнения 
MapReduce в таком случае является база данных: например такая, где по ID пользователя можно получить продукты, которые
ему понравятся. Наивная мысль, что MapReduce после этапа свертки отправляет такие данные куда-нибудь в MongoDB или 
PostgreSQL - это очень дорого и противоречит принципу отсутствия побочных результатов во время работы. Для таких целей
создается БД внутри пакетной задачи. Для таких целей подходят БД Voldemort, Terrapin, ElephantDB, HBase.

Задача MapReduce состоит из двух частей (двух функций):
1) Отображение (map) - функция отображения принимает на вход список значений и применяется к каждому элементу списка. 
Результатом функции служит другой список (может даже пустой) из объектов ключ-значение. Таким образом, на выходе из 
функции отображения может быть список большего или меньшего размера, чем исходный.
2) Свертка (reduce) - функция свертки преобразует список к некоему атомарному значению, которое нас интересует. Так же 
применяется поэлементно, но имеет промежуточный результат между выполнениями. 

Между Map и Reduce просходит процесс **shuffling**, в этом процессе все пары ключ-значения после функции отображения
группируются по ключу. Функция свертки применяется к группе значений по одному ключу.

Распределенная работа MapReduce (пояснения после картинки):
![img.png](../../../../img/highload/mapReduce.png)

Большой плюс MapReduce в возможности использовать распределенные вычисления. Данные, поступающие на вход, 
секционнируются. Обычно объем каждого входного файла составляет сотни мегабайт. Планировщик задач MapReduce запускает 
функцию отображения на каждой машине, где хранятся данные и где хватает памяти/процессорных мощностей для запуска этой 
функции. Данный принцип называется "где данные, там вычисления". Самого кода этой функции на машине нет, поэтому среда 
MapReduce сначала копирует код (JAR архив) на машину и затем запускает выполнение этого кода. Результат выполнения 
является список пар ключ-значение.

Для каждой такой пары ключ-значение после отображения вычисляется кеш по ключу. На основе этого ключа определяется, в 
какую машину направить такую пару. Все пары с одним ключом попадают на одну машину. На одной машине может быть несколько
разных ключей, но будет произведена группировка, поэтому сначала обработаются все пары по одному ключу, затем по 
другому.

Как на самом деле происходит шафлинг? Данных ведь много и не получится сначала все отобразить, как это сгруппировать и 
потом отправить на свертку - не хватит оперативной памяти. Для решения этой проблемы после функции отображения каждая 
машина сортирует какую-то часть данных, которую она только что обработала. Когда какая-то машина закончила и отсортировала 
данные - уведомляются машины с функцией свертки. Каждая машина свертки сходит к машине отображения и заберет необходимую ей
часть данных.

Обычно одна задача (функция отображения + функция свертки) может решить ограниченный круг задач: например посчитать сколько
раз купили тот или иной товар. Если же мы хотим решить более сложную проблему (например получить топ 10 самых 
продаваемых товаров), то нужно сделать еще одну задачу MapReduce (еще раз отфильтровать данные, полученные с первого
шага). Таким образом, в боевых примерах, MapReduce задачи представляют собой pipeline из задач, результат одной 
передается на вход другой.

Поговорим про **объединения (join)** в пакетной обработке, такой как MapReduce. Представим пример, что у нас есть 2 типа 
данных: данные пользователя и их действия. Перед нами стоит задача связать возраст пользователя с его действиями. 
Существует 2 подхода к решению данной задачи:

1) **Объединение на этапе свертки** (Reduce-side joins)
Функция отображения извлекает ключ и значение из полученных данных. У данных обоих типов есть общий ключ - ID 
пользователя. Таким образом одна функция отображения извлекает возраст пользователя по его ID, а вторая извлекает
действия пользователя по его ID. На этапе свертки такие данные сгруппируются по ключу - ID пользователя и мы получим 
данные о его действиях и возрасте в одном наборе данных.

![img.png](../../../../img/highload/reduce-side-joins.png)

2) **Объединение на этапе отображения** (Map-side joins)
Объединение на этапе свертки может потребовать довольно больших вычислительных затрат. Когда удается сделать 
определенные предположения о входных данных, можно ускорить объединение, используя map-side join. При таком подходе
используется упрощенная задача MapReduce без свертки и сортировки. Отображение просто читает один блок входных файлов и
записывает в файловую систему один выходной файл. 

Различают 3 типа объединения на этапе отображения:  
2.1) **Широковещательное объединение по хешу** - когда объединяем большой набор данных с небольшим. В таком случае
небольшой набор данных можно полностью загрузить в память машину выполняющей отображение.  
2.2) **Секционнированное хеш-объединение** - если оба источника одинаковых размеров, то можно поделить их на части так,
чтобы части полностью помещались в оперативную память. Вспомним пример с пользователями и действиями, в данном случае
можно загрузить в одну машину всех пользователей, чей ID заканчивается на 3 и действия таких пользователей.  
2.3) **Объединение слиянием нга этапе отображения** - если оба источника одинаковых размеров и отсортированы, то читать
из таких источников можно построчно, совмещая это с объединением. Напоминает логику сортировки слиянием.  

### За пределеами MapReduce
MapReduce - всего лишь одна из систем пакетной обработки данных. Однако эта система хорошо подходит для обучения, это
очень ясная и простая абстракция над распределенной файловой системой. Одна в использовании эта система не такая 
простая. Чистое API MapReduce сложное и трудоемкое, поэтому поверх него есть много высокоуровневых надстроек (Pig, Hive, 
Cascading, etc). 

Одним из минусов MapReduce является генерацией промежуточных данных. Чтобы передать данные из одной задачи в другую, 
MapReduce записывает данные в файл на диск. Этот процесс называется материализацией. В Unix системах (прородители
системы MapReduce) вместо файлов используются потоки передачи данных, которые используют лишь небольшой буфер памяти.
У процесса материализации есть следующие минусы:
1) Задача MapReduce запускается только после того, как предыдущая задача полностью была выполнена и записала все 
выходные в файл. В некоторых случаях можно ускорить выполнение, если выполнять задачи по мере поступления данных.
2) Зачастую функции отображения являются избыточными, так как они просто читают входной файл. Удобнее было бы писать
сразу несколько функций свертки подряд.
3) Сохранение промежуточного результата требует наличие дискового пространства и замедляется из-за этой записи на 
постоянный носитель.

Чтобы решить проблемы MapReduce было разработано несколько новых механизмов для выполнения распределенных пакетных
вычислений на основе MapReduce. Такие инструменты: Apache Spark, Tez, Flink, etc. Поскольку в этих системах не 
используется материализация, их еще иногда называют _подсистемами потока данных_. Благодаря различным оптимизациям 
подсистемы потока данных выполняются быстрее, чем MapReduce.

## Резюме
MapReduce - система для пакетной обработки большого (петабайты) объема данных. Во многом технология наследует философию
Unix. Часть философии заключается в том, что входные данные неизменяемы, а выходные предназначены служить входными
для другой программы. В мире Unix данные передаются потоком при помощи общего интерфейса. MapReduce передает данные от
задачи к задаче с помощью записи данных в файлы на диск распределенной системы (процесс называется материализация).
Инструменты разработанные поверх системы MapReduce позволяют избавиться от материализации и использовать прямую передачу
потока данных, используя небольшой буфер в памяти.

Существует несколько алгоритмов объединения (join) в MapReduce: 
1) **Reduce-side join** - функция отображения извлекает ключ объединения. Все записи с одинаковым ключом попадают в одну
группу для обработки функцией свертки. Эта функция свертки и производит объединение
2) **Map-side joins. Широковещательное объединение по хешу** - когда один из объединяемых наборов данных мал, он может
быть полностью загружен в оперативную память машины выполняющей операцию отображения. Функция отображения для каждой 
записи входных данных сходит в оперативную память и найдет соответствующую запись из второго набора данных.
3) **Map-side joins. Секционнированное хеш-объединение** - оба набора одинакового размера и возможно произвести 
секционирование по одному ключу. Таким образом любой из наборов можно загрузить в хеш таблицу в памяти.

Благодаря тому, что задачи MapReduce не меняют состояние входных данных и не генерируют внешних побочных эффектов (кроме 
выходных данных). Сама система, вместо нас, может обеспечивать отказоустойчивость. В случае какой-то проблемы достаточно 
перезапустить часть задач (они безопасно повторяются из-за детерминированности).