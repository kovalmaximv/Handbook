# Kafka
Kafka - распределенный брокер сообщений, поддерживающий высокую нагрузку.

Kafka - CA по CAP теореме.

Свойства Kafka:
1) Распределенность
2) Отказоустойчивость
3) Высокая доступность
4) CA - согласованность и надежность
5) Высокая производительность
6) Горизонтальная масштабируемость
7) Популярное решение

Задача брокера сообщений - доставка сообщений от Producer к Consumer. 

### Схема компонентов кафки
![img.png](../../../img/kafka/kafka_components.jpg)

1) Zookeeper - инструмент для координации. Следит за состоянием узлов и исходя из этого координирует чтение/запись.
   В 2024 году планируется отказаться от Zookeeper в пользу встроенный в кафку KRaft.
2) Kafka cluster - сервер, содержащий брокеры.
3) Kafka Brokers - инстансы кафки, содержащий топики и отвечающий за передачу сообщений.
3) Kafka Topic - непосредственно топик, хранящий сообщения.
4) Consumer/Producer - отправитель и получатель данных.

### Топики
Топик - хранилище единых событий, делится на партиции. Партиции топика работают по принципу FiFo. При чтении из 
партиции данные не удаляются.

Внутри партиции и находится очередь из сообщений. Механизм партиций необходим для распаралеливания процесса. Ведь вместо
того, чтобы читать всем из одной большой очереди, лучше разделить очередь на очереди поменьше и читать уже **без 
конкурентного** доступа оттуда. Каждую партицию читает только один Consumer из группы. Сообщения между партициями 
разделяются на основе некоторых правил, упрощено можно считать, что сообщение может попасть в любую
из партиций и распределение между партициями равномерное. Таким образом, для высоконагруженных систем можно сделать
кучу партиций, поднять кучу инстансов сервисов и держать таким образом большую нагрузку.

Сохранение очередности чтения гарантируется на уровне партиции, но не топика.

Все партиции распределяются по брокерам. Но может случиться такое, что все партиции одного топика окажутся в одном 
брокере. Связано это с тем, что партиции разбиваются случайно на равное количество партиций для каждого брокера, 
принадлежность к топику не учитывается. Если разброс партиций оказался неравномерным, перенести их можно вручную.

Данные топиков хранятся в `.log` файлах. Под каждую партицию есть папка, где в `.log` файлах хранятся данные:
1) `00...0000.log` - файл для хранения offset (номера сообщения в партиции), position (байтовое смещение для сообщений),
timestamp, message.
2) `00...0000.index` - файл для определения смещения для быстрого чтения. Хранит offset и position.
3) `00...0000.timeindex` - файл для определения смещения относительно времени, например для чтения данных за прошлую 
неделю. Хранит offset и timestamp.

Номер в названии файла - offset первого элемента в этом файле. При превышении файла по лимиту времени/места создаются 
3 новых файла с новым названием, старые временно остаются и потом удалятся. Все 3 файла вместе называются сегментом.

В Kafka нет операции удаления данных из очереди, есть только периодическая чистка старых неиспользуемых сегментов.

### Репликации
`replication_factor` - сколько реплик создавать для каждой партиции. Реплики находятся в разных брокерах. Реплики 
используют схему Master-Slave. Одна партиция выбирается мастером и все операции чтения и записи (по умолчанию) происходят 
только через нее. Мастер партиций нужно раскидывать по разным брокерам для равномерной нагрузки.

Из-за того, что фоловеры опрашивают мастера для получения новых данных -> могут быть отставания данных между
мастером и фоловером. А значит, если лидер упал и фоловеры не успели получить последние данные, то данные могут быть
утрачены. 

Для решения этой проблемы в кафке есть insync replicas. Это те реплики, в которые мастер синхронно записывает новые 
данные. Такие реплики называются ISR. Количество таких ISR реплик задается настройкой: `min.insync.replicas`, значение 
настройки нельзя задавать больше, чем кол-во реплик -1. На случай если одна реплика упадет, партиция окажется 
работоспособной.

### Producer
Для Producer есть много параметров, но вот один из самых важных (часто спрашивают на собесах): **acks** (гарантия доставки)

**0** - не ждет подтверждения отправки (самый быстрый способ, но могут теряться сообщения).  
**1** - ждет подтверждения только от мастер реплики (если мастер реплика упадет не успев передать данные - потеряем сообщение).  
**-1(all)** - подтверждения от мастер и ISR реплик (сообщения точно не потеряются).  

Чаще всего выбирают `acks = 1` как компромисс между быстродействием и надежностью.

Так же можно задать, в какую партицию отправить сообщения:
1) Задать определенную партицию
2) round_robin - нам не важно, решит брокер
3) по кешу ключа

Флоу отправки сообщения:
1) Producer.sendMessage
2) fetchMetadata (обращение в Zookeeper)
3) serializeMessage
4) definePartition
5) compress message
6) accumulate batch - по batch_size либо timeout отправки
7) сообщение отправлено

### Consumer
Все получатели объединяются в группы (consumer group). Например, может быть несколько групп (аналитиков, безопасников,
бизнес сервисов) и каждая из групп читает сообщение из топика для своих целей. Важно, что каждая группа читает топик
**независимо** и не мешая друг другу. Если группа аналитиков прочитала 35 сообщение из очереди и упало, то это не
помешает другим группам (они даже ничего не узнают) и после сбоя группа аналитиков сможет читать сообщения с того же
места. Таким образом чтение происходит быстрее из-за нескольких consumer.

Одну партицию может читать максимум один consumer. 

Offset - номер последнего сообщения из партиции, который прочитала данная consumer группа. Offset хранится в служебном
топике Kafka `__consumer_offsets`, где хранится offset для каждой пары партиция-группа (Partition, Group, Offset).

После обработки Consumer отправляет commit в `__consumer_offsets` и offset для данной группы меняется. Если consumer
упал, новый consumer в группе подгрузит offset из этой очереди. 

Commit может быть:
1) Auto (гарантия at most once) - как только получил сообщения - сразу commit. Если упал на обработке, сообщение потеряно.
2) Manual (гарантия at least once) - commit вручную после того, как обработал сообщение.
3) Custom offset management (exactly once) - отказывается от служебного топика и хранит offset сами. Логику commit 
реализовываем тоже сами. 

Offset может пропасть, если consumer долго не читал сообщения. На это влияет настройка `offsets.retention.minutes`, 
по умолчанию 7 дней.

### Consumer rebalancing
Когда добавляется новая партиция, падает или появляется новый consumer - запускается процесс ребалансировки. Суть 
процесса в том, чтобы заново распределить партиции по consumer.

В идеале, когда на каждую партицию есть по consumer. В таком случае при добавлении нового consumer ничего не произойдет,
поскольку одну партицию может читать максимум один consumer. 

В любом другом случае есть два сценария:
1) Ребалансировка stop-the-world - все consumer останавливаются, мастер брокер заново распределяет партиции между
consumer.
2) Кооперативная ребалансировка - consumer продолжают работу, партиции без чтецов распределяются по consumer.